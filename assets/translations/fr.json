{
    "header": {
        "nav": {
            "home": "Accueil",
            "education": "Études",
            "experience": "Expérience",
            "publications": "Publications",
            "projects": "Projets",
            "skills": "Compétences"
        }
    },
    "index": {
        "title": "Doctorant en informatique à l'Université Laval",
        "location": "Québec, QC, Canada",
        "website": "Site Web",
        "aboutTitle": "À propos",
        "aboutText": "Je suis doctorant en informatique à Université Laval (Canada), spécialisé dans l'architecture logicielle basée sur l'intelligence artificielle et les systèmes distribués. Mes recherches portent sur le développement d'approches intelligentes pour la décomposition automatisée en microservices, ayant abouti à quatre publications évaluées par des pairs dans des revues prestigieuses, notamment EMSE et IST. J'ai précédemment obtenu une maîtrise en Systèmes Intelligents de École Nationale des Sciences de l’Informatique (Tunisie), avec une spécialisation en apprentissage profond. Parfaitement bilingue français-anglais, je combine une expertise théorique en apprentissage automatique avec une solide expérience pratique en technologies cloud-native (Kubernetes, Docker), en conception de systèmes distribués et en frameworks d'apprentissage automatique (PyTorch, Transformers).",
        "researchTitle": "Recherche",
        "researchText": "Bien que l'architecture en microservices ait prouvé son efficacité pour les applications à grande échelle grâce à sa modularité et sa compatibilité cloud, la migration d'un système monolithique établi vers une architecture en microservices reste un processus coûteux et complexe. L'étape critique de décomposition, qui consiste à partitionner les composants du monolithe en microservices cibles, a été identifiée comme l'obstacle principal.\n<br>Ma thèse se concentre sur l'étude des approches automatisées de décomposition et de refactoring dans le but de moderniser le processus de migration et de modernisation des architectures logicielles. J'introduis des approches basées sur l'IA, allant des algorithmes évolutionnaires à l'apprentissage par représentation basé sur les LLM, pour améliorer l'efficacité des approches de décomposition et fournir de meilleures recommandations de microservices. De plus, cette thèse présente une approche permettant de refactoriser automatiquement les interactions monolithiques en RPC en utilisant une combinaison de modèles d'IA générative et de méthodes de méta-modélisation.",
        "researchInterestsTitle": "Intérêts de recherche:",
        "researchInterests": "Intelligence Artificielle, Apprentissage Automatique, Apprentissage Profond, Microservices, Refactoring de Code, Cloud",
        "newsTitle": "Actualités",
        "resumeTitle": "CV",
        "resumePath": "/assets/pdfs/khaled_sellami_cv.pdf"
    },
    "education": {
        "pageTitle": "Études",
        "coreCourses": "Cours Principaux",
        "phd": {
            "location": "Québec, QC, Canada",
            "dates": "(Mai 2021 - Présent)",
            "degree": "Doctorat en informatique",
            "courses": {
                "nlp": "IFT-4022: Traitement du langage naturel",
                "rl": "IFT-7201: Apprentissage par renforcement",
                "bigdata": "GLO-7027: Traitement des données massives",
                "cloud": "GLO-7008: Applications Cloud Native et DevOps"
            }
        },
        "masters": {
            "location": "Tunis, Tunisie",
            "dates": "(Septembre 2017 - Septembre 2020)",
            "degree1": "M.Sc. en informatique",
            "degree2": "Diplôme d'ingénieur en informatique",
            "school": "École Nationale des Sciences de l'Informatique (ENSI)",
            "courses": {
                "ai": "Intelligence Artificielle",
                "ml": "Apprentissage Automatique et Profond",
                "cloud": "Cloud Computing",
                "bigdata": "Données Massives",
                "arch": "Architecture Logicielle",
                "algo": "Algorithmes, Structures de Données et Programmation C"
            }
        },
        "prep": {
            "location": "Tunis, Tunisie",
            "dates": "(Septembre 2015 - Juin 2017)",
            "degree": "Mathématiques et Physique",
            "school": "Institut Préparatoire aux Études d'Ingénieur de Tunis (IPEIT)",
            "courses": {
                "math": "Analyse Mathématique",
                "algebra": "Algèbre et Algèbre Linéaire",
                "physics": "Physique",
                "cs": "Informatique"
            }
        }
    },
    "projects": {
        "pageTitle": "Projets",
        "affiliation": "Affiliation:",
        "references": "Références:",
        "microanalyzer": {
            "dates": "(Juin 2024)",
            "description": "Une collection d'outils d'analyse statique pour divers langages de programmation (Java, C#, Python, JavaScript, Ruby, Go). Dans le cadre d'un article de recherche plus vaste, ce projet implémente un ensemble de parseurs permettant d'extraire des extraits de code dans des applications basées sur des microservices pour plusieurs langages de programmation."
        },
        "rldec": {
            "dates": "(Mai 2023)",
            "description1": "Ce projet est une implémentation de l'approche de décomposition RLDec décrite dans l'article",
            "description2": "RLDec est un outil de décomposition qui analyse le code source d'une application Java monolithique et suggère les microservices recommandés pour chaque classe du système en utilisant une méthode basée sur l'apprentissage par renforcement profond. L'approche a été principalement implémentée avec PyTorch et Ray-RLlib, une bibliothèque d'apprentissage par renforcement offrant une API de haut niveau pour l'apprentissage par renforcement distribué."
        },
        "hydec": {
            "dates": "(Décembre 2022)",
            "description1": "Ce projet est une implémentation des approches de décomposition HyDec et HierDec décrites dans les articles:",
            "description2": "HierDec est un outil de décomposition qui analyse le code source d'une application Java monolithique à l'aide d'une analyse statique et d'un pipeline basé sur TF-IDF. Il recommande les microservices appropriés pour chaque classe du système en utilisant une version hiérarchique de l'algorithme DBSCAN.\n\nHyDec est une extension de l'approche HierDec qui combine les résultats de l'analyse statique avec ceux de l'analyse dynamique afin d'améliorer la qualité de la décomposition.\n\nL'implémentation actuelle est une généralisation de l'approche proposée dans HyDec, permettant l'utilisation de diverses représentations du code source (avec ou en remplacement des résultats des analyses statique et dynamique). Elle inclut les configurations par défaut correspondant aux approches décrites dans les articles de HyDec et HierDec."
        },
        "msextractor": {
            "dates": "(Janvier 2022)",
            "description1": "Ce projet est une implémentation de l'approche de décomposition MSExtractor décrite dans l'article",
            "description2": "MSExtractor est un outil de décomposition qui analyse le code source d'une application Java monolithique et suggère les microservices recommandés pour chaque classe du système en utilisant l'algorithme évolutionnaire IBEA (Indicator-Based Evolutionary Algorithm)."
        },
        "sunflower": {
            "title": "Classification automatique de graines de tournesol basée sur des images Rayons-X",
            "dates": "(Mars 2020 - Août 2020)",
            "description": "Ce projet a été réalisé dans le cadre de mon stage de fin d'études chez Vilmorin Mikado. L'objectif était de développer un modèle d'apprentissage automatique capable de classer les graines de tournesol à partir d'images radiographiques. Le projet s'est articulé autour de trois principales parties :",
            "parts": "<li>Développement d'un module de segmentation pour extraire les graines des images radiographiques en utilisant des techniques classiques de traitement d'image</li> <li>Construction du module de classification, incluant la recherche du meilleur modèle à utiliser, le prétraitement des données et l'entraînement du modèle de réseau de neurones convolutionnel (CNN) sur les images au format DICOM</li> <li>Développement d'une interface conviviale permettant aux utilisateurs de téléverser les images, les examiner, les modifier, obtenir les résultats de classification et affiner les résultats générés</li>"
        },
        "foodies": {
            "school": "École Nationale des Sciences de l'Informatique (ENSI)",
            "dates": "(Janvier 2019 - Avril 2019)",
            "description": "Ce projet a été réalisé dans le cadre de mes études pour le cours « Design and Development », où nous devions développer un logiciel de l'idée initiale jusqu'au déploiement. Ce projet est un système de recommandation de recettes de cuisine tunisienne basé sur les ingrédients. L'application utilise des techniques de Data Mining pour traiter les ingrédients, des techniques d'apprentissage automatique pour construire le moteur de recommandation, ainsi qu'une application web Django pour héberger le système."
        }
    },
    "publications": {
        "pageTitle": "Publications",
        "peerReviewed": "Publications Évaluées par les Pairs"
    },
    "skills": {
        "pageTitle": "Compétences",
        "languages": {
            "title": "Langages de Programmation/Scripting",
            "expert": "Expert",
            "advanced": "Avancé",
            "working": "Intermédiaire",
            "basic": "Débutant"
        },
        "frameworks": {
            "title": "Frameworks",
            "datascience": "Science des Données & ML",
            "visualization": "Visualisation",
            "web": "Frameworks Web"
        },
        "cloud": {
            "title": "Cloud et MLOps"
        },
        "tools": {
            "title": "Outils et Environnements"
        },
        "databases": {
            "title": "Bases de Données"
        }
    },
    "footer": {
        "quickLinks": "Liens Rapides"
    }
}